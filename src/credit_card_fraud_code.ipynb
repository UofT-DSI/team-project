{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import confusion_table\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"../data/card_transdata.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "# Visualize the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the distribution of all variables\n",
    "df.hist(bins=20, figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the multiple regression on multiple columns which seem to have a correlation with the output \n",
    "y = df['fraud']\n",
    "X = MS(['distance_from_home','distance_from_last_transaction','ratio_to_median_purchase_price','repeat_retailer','used_chip','used_pin_number','online_order']).fit_transform(df) \n",
    "#X = df.drop('fraud', axis='columns')\n",
    "#X = sm.add_constant(X)\n",
    "model1 = sm.OLS(y, X)\n",
    "results1 = model1.fit()\n",
    "summarize(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression with interaction between two fields to test their combined effect\n",
    "model = sm.OLS.from_formula('fraud ~ distance_from_home * distance_from_last_transaction', data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression with variable interactions between multiple variables\n",
    "model = sm.OLS.from_formula('fraud ~ distance_from_last_transaction * ratio_to_median_purchase_price* distance_from_home* used_chip', data=df)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictors (excluding the last column)\n",
    "predictors = df.iloc[:, :-1]\n",
    "# Standardize the predictors\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())\n",
    "# Create a random vector of True and False values\n",
    "np.random.seed(4)\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = df.loc[split, 'fraud']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = df.loc[~split, 'fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try the KNN model and view the confusion table results\n",
    "knn = KNeighborsClassifier(n_neighbors =3)\n",
    "knn_fit=knn.fit(training_X,training_Y)\n",
    "knn_pred = knn.predict(testing_X)\n",
    "confusion_table(knn_pred,testing_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the prediction accuracy\n",
    "prediction_accuracy = knn.score(testing_X,testing_Y)\n",
    "print(prediction_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with imbalanced data\n",
    "\n",
    "We can see that KNN was really effective, however we still fail to detect 204/21906 cases of fraud, almost 1 in 100. \n",
    "\n",
    "Can we get closer to understanding the predictors of credit card fraud by balancing out the data through subsampling? Subsampling will repeat the analysis using a dataframe that is 50/50 fraud and not-fraud.\n",
    "\n",
    "This will help us enhance the fraud signal and create a more proactive fraud catching model. It will also help clarify the direction and relative magnitude of correlations between fraud and the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = 5\n",
    "np.random.seed(s) \n",
    "\n",
    "df_fraud = df.loc[df.fraud==True]\n",
    "df_full_notfraud = df.loc[df.fraud==False]\n",
    "undersplit = np.random.choice([True, False], size=len(df_full_notfraud), replace=True, p=[0.5, 0.5])\n",
    "df_under_notfraud = df_full_notfraud[undersplit][:len(df_fraud)]\n",
    "\n",
    "df_subsample_0 = pd.concat([df_under_notfraud,df_fraud])\n",
    "df_subsample = df_subsample_0.sample(frac=1, random_state=s)\n",
    "\n",
    "print(len(df_subsample) == 2*len(df_fraud))\n",
    "df_subsample\n",
    "\n",
    "df_subsample.to_csv('subsample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data frame ```df_subsample``` to work with. ```df_subsample``` has data containing all of the frauds from the original dataset as well as an equal number of randomly selected non-frauds. If we change the seed parameter s, then an entirely different set of non-frauds can be drawn. This can help us to vary the outcomes of the experiment which will allow us to bootstrap measure the standard error of our correlations and our predicted accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax1)\n",
    "ax1.set_title(\"Original Correlation Matrix)\", fontsize=14)\n",
    "\n",
    "corr_subsample_matrix = df_subsample.corr()\n",
    "sns.heatmap(corr_subsample_matrix, annot=True, cmap='coolwarm', ax=ax2)\n",
    "ax2.set_title('Subsampled Correlation Matrix)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown above are the correclation matrices for our dataframes. Wee see the signal of our correlations has been enhanced. We might expect that fitting on this subsample and testing on the full_sample we will reduce the false_negative (not fraud labels applied to frauds) by a factor of 1/50. By the same logic this validation should increase the false positives (fraud labels applied to non_frauds) 50times. We would then have a model that reduces undetected frauds from 1 missed fraud in 100 frauds to 1 missed fraud in 4,000 frauds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
